{"config":{"lang":["en"],"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"SKIL: Deep learning model lifecycle management for humans Python client for Skymind's intelligence layer (SKIL) SKIL is an end-to-end deep learning platform. Think of it as a unified front-end for your deep learning training and deployment process. SKIL supports many popular deep learning libraries, such as Keras, TensorFlow and Deeplearning4J. SKIL increases time-to-value of your AI applications by closing the common gap between experiments and production - bringing models to production fast and keeping them there. acting as middleware for all your AI applications. SKIL effectively acts as middleware for your AI applications and solves a range of common production problems of, namely: Install and run anywhere: SKIL integrates with your current cloud provider, custom on-premise solutions and hybrid architectures. Easy distributed training on Spark: Bring your Keras or TensorFlow model and train it on Apache Spark without any overhead. We support a wide variety of distributed data sources and other vital parts of your production stack. Seamless deployment process: With SKIL, your company's machine learning product lifecycle can be as quick as your data scientist\u2019s experimentation cycle. If you set up a SKIL experiment, model deployment is already accounted for, and makes product integration of deep learning models into a production-grade model server simple - batteries included. Built-in reproducibility and compliance: What model and data did you use? Which pre-processing steps were done? Who carried out the experiment? What library versions were used? Which hardware was utilized? SKIL keeps track of all this information for you. Model organisation and versioning: SKIL makes it easy to keep your various experiments organised, without interfering with your workflow. Your models are versioned and can be updated at any point. Keep working as you're used to: SKIL does not impose an entirely new workflow on you or force you into a UI, just stay right where you are. Happy with your experiment and want to deploy it? Tell SKIL to deploy a service. Your prototype works and you want to scale out training with Spark? Tell SKIL to run a training job. Installation To install SKIL itself, head over to skymind.ai . Probably the easiest way to get started is by using docker : docker pull skymindops/skil-ce docker run --rm -it -p 9008:9008 skymindops/skil-ce bash /start-skil.sh SKIL's Python client can be installed from PyPI: pip install skil Getting started: Deploying an object detection app with SKIL in 60 seconds We're going to deploy an object detection model pre-trained with Google TensorFlow. The model we use is the second version of the You Only Look Once (YOLOv2) model trained on the COCO dataset. Download this model from here and store it as yolo.pb . If you haven't done already, install and start SKIL as described in the last section. For this quick example you only need three (self-explanatory) concepts from SKIL. You first create a Model from the model file yolo.pb you just downloaded. This Model becomes a SKIL Service by deploying it to a SKIL Deployment . That's all there is to it: import skil model = skil.Model('yolo.pb', model_id='yolo_42', name='yolo') service = model.deploy(skil.Deployment(), input_names=['input'], output_names=['output']) Your YOLO object detection app is now live and you can send images to it using the detect_objects method of your service . We use OpenCV (imported as cv2 into Python) to load, annotate and write images: import cv2 image = cv2.imread(\"say_yolo_again.jpg\") detection = service.detect_objects(image) image = skil.utils.yolo.annotate_image(image, detection) cv2.imwrite('annotated.jpg', image) This completes your very first SKIL example, but there are many more advanced examples to get you started: Running YOLO against a live web cam Deploying a Keras model as prediction service to SKIL Deploying a TensorFlow model as prediction service to SKIL Using SKIL's CLI to quickly configure models and deployments Deploying a Keras model from a jupyter notebook WIP Run a Spark training job from a simple Keras model WIP Deploy preprocessing steps and a model as a Pipeline service","title":"Home"},{"location":"#skil-deep-learning-model-lifecycle-management-for-humans","text":"","title":"SKIL: Deep learning model lifecycle management for humans"},{"location":"#python-client-for-skyminds-intelligence-layer-skil","text":"SKIL is an end-to-end deep learning platform. Think of it as a unified front-end for your deep learning training and deployment process. SKIL supports many popular deep learning libraries, such as Keras, TensorFlow and Deeplearning4J. SKIL increases time-to-value of your AI applications by closing the common gap between experiments and production - bringing models to production fast and keeping them there. acting as middleware for all your AI applications. SKIL effectively acts as middleware for your AI applications and solves a range of common production problems of, namely: Install and run anywhere: SKIL integrates with your current cloud provider, custom on-premise solutions and hybrid architectures. Easy distributed training on Spark: Bring your Keras or TensorFlow model and train it on Apache Spark without any overhead. We support a wide variety of distributed data sources and other vital parts of your production stack. Seamless deployment process: With SKIL, your company's machine learning product lifecycle can be as quick as your data scientist\u2019s experimentation cycle. If you set up a SKIL experiment, model deployment is already accounted for, and makes product integration of deep learning models into a production-grade model server simple - batteries included. Built-in reproducibility and compliance: What model and data did you use? Which pre-processing steps were done? Who carried out the experiment? What library versions were used? Which hardware was utilized? SKIL keeps track of all this information for you. Model organisation and versioning: SKIL makes it easy to keep your various experiments organised, without interfering with your workflow. Your models are versioned and can be updated at any point. Keep working as you're used to: SKIL does not impose an entirely new workflow on you or force you into a UI, just stay right where you are. Happy with your experiment and want to deploy it? Tell SKIL to deploy a service. Your prototype works and you want to scale out training with Spark? Tell SKIL to run a training job.","title":"Python client for Skymind's intelligence layer (SKIL)"},{"location":"#installation","text":"To install SKIL itself, head over to skymind.ai . Probably the easiest way to get started is by using docker : docker pull skymindops/skil-ce docker run --rm -it -p 9008:9008 skymindops/skil-ce bash /start-skil.sh SKIL's Python client can be installed from PyPI: pip install skil","title":"Installation"},{"location":"#getting-started-deploying-an-object-detection-app-with-skil-in-60-seconds","text":"We're going to deploy an object detection model pre-trained with Google TensorFlow. The model we use is the second version of the You Only Look Once (YOLOv2) model trained on the COCO dataset. Download this model from here and store it as yolo.pb . If you haven't done already, install and start SKIL as described in the last section. For this quick example you only need three (self-explanatory) concepts from SKIL. You first create a Model from the model file yolo.pb you just downloaded. This Model becomes a SKIL Service by deploying it to a SKIL Deployment . That's all there is to it: import skil model = skil.Model('yolo.pb', model_id='yolo_42', name='yolo') service = model.deploy(skil.Deployment(), input_names=['input'], output_names=['output']) Your YOLO object detection app is now live and you can send images to it using the detect_objects method of your service . We use OpenCV (imported as cv2 into Python) to load, annotate and write images: import cv2 image = cv2.imread(\"say_yolo_again.jpg\") detection = service.detect_objects(image) image = skil.utils.yolo.annotate_image(image, detection) cv2.imwrite('annotated.jpg', image) This completes your very first SKIL example, but there are many more advanced examples to get you started: Running YOLO against a live web cam Deploying a Keras model as prediction service to SKIL Deploying a TensorFlow model as prediction service to SKIL Using SKIL's CLI to quickly configure models and deployments Deploying a Keras model from a jupyter notebook WIP Run a Spark training job from a simple Keras model WIP Deploy preprocessing steps and a model as a Pipeline service","title":"Getting started: Deploying an object detection app with SKIL in 60 seconds"},{"location":"core_concepts/","text":"SKIL core concepts To get started with SKIL, you should know about a few core concepts of it. Here's a bird's eye view of what SKIL does. We'll go through each concept quickly one by one. Most concepts should feel familiar, as they come up naturally in most data science workflows. Workspaces : Whatever you do with SKIL, you start with a WorkSpace . It's a collection of all the work that belongs together. This could be all the work your department does, a one-off project you're tackling, or all experiments you conducted on a specific topic. You can freely choose how to scope your workspaces. Experiments : Once you have a workspace to work with, the next step is to create an Experiment in it. An experiment is what you inuitively might think it is: a data science experiment, in which you can explore data, prototype models, visualize outcomes etc. If you like, you can think of an experiment as a notebook that collects your work session (and in fact the SKIL UI equips each experiment with a notebook for you out of the box). You can create unlimited experiments within a workspace. Models : If you're happy with an experiment, you usually want to take the next step and productionize your work. The SKIL Model concept helps you do that. SKIL currently support TensorFlow, Keras and DL4J models as Model . Putting a model to production can mean several things. You either want to do scale-out, production grade training on a cluster or deploy your model as a service (training or inference), tasks you can't do on your local machine. SKIL Model s are the basis for each of these production steps. Deployments : Let's say you have conducted one or several experiments, found a model that's a clear winner and want to get it to production quickly. You do this by creating a SKIL Deployment and deploy your Model . Services : A deployed model is a Service . SKIL offers several services, depending on what you want to deploy (e.g. only a model, only a pre-processing step, a pipeline consiting of several transforms and a models etc.). For now the only thing you need to know is that a service takes your work and puts it into a production-grade service that you and your team can easily use to get predictions (inference). Jobs : If, instead of deploying a trained model, you want to run a training job that scales out model training on a massive dataset using Apache Spark, a SKIL Job is what you want. To run a training job you need to specify where the data is, what your compute resources are and how you want to distribute training (relating to the last three concepts we will cover here). Training jobs will usually produce an output for you and will result in trained models that you can deploy as service, exactly as described before. It is also possible to run distributed inference jobs , in case you have massive amounts of data that needs to pass through a trained model. That's also possible with SKIL, and works pretty much the same way as setting up a training job. Distributed job configuration : Running a model locally and running it distributed on Spark can be very different. A DistributedConfiguration specifies how exactly your model should be distributed (for instance whether to use parameter averaging or sharing). Compute resources : Tells a job what compute capabilities it can use. A ComputeResource can for instance be AWS Elastic Map Reduce (EMR), Google Cloud DataProc, Azure HDInsight, or any Spark cluster that you might have on premise. Storage resources : Tells a job where the data it uses is located. A StorageResouce could be an Azure container, Google cloud storage, Amazon S3 or HDFS.","title":"SKIL core concepts"},{"location":"core_concepts/#skil-core-concepts","text":"To get started with SKIL, you should know about a few core concepts of it. Here's a bird's eye view of what SKIL does. We'll go through each concept quickly one by one. Most concepts should feel familiar, as they come up naturally in most data science workflows. Workspaces : Whatever you do with SKIL, you start with a WorkSpace . It's a collection of all the work that belongs together. This could be all the work your department does, a one-off project you're tackling, or all experiments you conducted on a specific topic. You can freely choose how to scope your workspaces. Experiments : Once you have a workspace to work with, the next step is to create an Experiment in it. An experiment is what you inuitively might think it is: a data science experiment, in which you can explore data, prototype models, visualize outcomes etc. If you like, you can think of an experiment as a notebook that collects your work session (and in fact the SKIL UI equips each experiment with a notebook for you out of the box). You can create unlimited experiments within a workspace. Models : If you're happy with an experiment, you usually want to take the next step and productionize your work. The SKIL Model concept helps you do that. SKIL currently support TensorFlow, Keras and DL4J models as Model . Putting a model to production can mean several things. You either want to do scale-out, production grade training on a cluster or deploy your model as a service (training or inference), tasks you can't do on your local machine. SKIL Model s are the basis for each of these production steps. Deployments : Let's say you have conducted one or several experiments, found a model that's a clear winner and want to get it to production quickly. You do this by creating a SKIL Deployment and deploy your Model . Services : A deployed model is a Service . SKIL offers several services, depending on what you want to deploy (e.g. only a model, only a pre-processing step, a pipeline consiting of several transforms and a models etc.). For now the only thing you need to know is that a service takes your work and puts it into a production-grade service that you and your team can easily use to get predictions (inference). Jobs : If, instead of deploying a trained model, you want to run a training job that scales out model training on a massive dataset using Apache Spark, a SKIL Job is what you want. To run a training job you need to specify where the data is, what your compute resources are and how you want to distribute training (relating to the last three concepts we will cover here). Training jobs will usually produce an output for you and will result in trained models that you can deploy as service, exactly as described before. It is also possible to run distributed inference jobs , in case you have massive amounts of data that needs to pass through a trained model. That's also possible with SKIL, and works pretty much the same way as setting up a training job. Distributed job configuration : Running a model locally and running it distributed on Spark can be very different. A DistributedConfiguration specifies how exactly your model should be distributed (for instance whether to use parameter averaging or sharing). Compute resources : Tells a job what compute capabilities it can use. A ComputeResource can for instance be AWS Elastic Map Reduce (EMR), Google Cloud DataProc, Azure HDInsight, or any Spark cluster that you might have on premise. Storage resources : Tells a job where the data it uses is located. A StorageResouce could be an Azure container, Google cloud storage, Amazon S3 or HDFS.","title":"SKIL core concepts"},{"location":"deployment/","text":"SKIL Deployments [source] Deployment skil.deployments.Deployment(skil=None, name=None, deployment_id=None) Deployments operate independently of workspaces to ensure that there are no accidental interruptions or mistakes in a production environment. Arguments: skil : Skil server instance. name : string. Name for the deployment. id : Unique id for the deployment. If None , a unique id will be generated.","title":"Deployments"},{"location":"deployment/#skil-deployments","text":"[source]","title":"SKIL Deployments"},{"location":"deployment/#deployment","text":"skil.deployments.Deployment(skil=None, name=None, deployment_id=None) Deployments operate independently of workspaces to ensure that there are no accidental interruptions or mistakes in a production environment. Arguments: skil : Skil server instance. name : string. Name for the deployment. id : Unique id for the deployment. If None , a unique id will be generated.","title":"Deployment"},{"location":"experiment/","text":"SKIL Experiments [source] Experiment skil.experiments.Experiment(work_space=None, experiment_id=None, name='experiment', description='experiment', verbose=False, create=True) Experiments in SKIL are useful for defining different model configurations, encapsulating training of models, and carrying out different data cleaning tasks. Experiments have a one-to-one relationship with Notebooks and have their own storage mechanism for saving different model configurations when seeking a best candidate. Arguments: work_space : WorkSpace instance. If None a workspace will be created. experiment_id : integer. Unique id for workspace. If None , a unique id will be generated. name : string. Name for the experiment. description : string. Description for the experiment. verbose : boolean. If True , api response will be printed. create : boolean. If True a new experiment will be created.","title":"Experiments"},{"location":"experiment/#skil-experiments","text":"[source]","title":"SKIL Experiments"},{"location":"experiment/#experiment","text":"skil.experiments.Experiment(work_space=None, experiment_id=None, name='experiment', description='experiment', verbose=False, create=True) Experiments in SKIL are useful for defining different model configurations, encapsulating training of models, and carrying out different data cleaning tasks. Experiments have a one-to-one relationship with Notebooks and have their own storage mechanism for saving different model configurations when seeking a best candidate. Arguments: work_space : WorkSpace instance. If None a workspace will be created. experiment_id : integer. Unique id for workspace. If None , a unique id will be generated. name : string. Name for the experiment. description : string. Description for the experiment. verbose : boolean. If True , api response will be printed. create : boolean. If True a new experiment will be created.","title":"Experiment"},{"location":"inference/","text":"Getting started with running model inference in SKIL","title":"SKIL inference"},{"location":"inference/#getting-started-with-running-model-inference-in-skil","text":"","title":"Getting started with running model inference in SKIL"},{"location":"jobs/","text":"SKIL Jobs [source] InferenceJobConfiguration skil.jobs.InferenceJobConfiguration(skil_model, batch_size, compute_resource, storage_resource, output_path, data_set_provider_class, is_multi_data_set=False, verbose=False) InferenceJobConfiguration Configuration for a SKIL inference job. On top of what you need to specify for a base JobConfiguration, you need to set the batch size for the model as well. Arguments: skil_model : a skil.Model instance batch_size : int, data batch size to run inference with on the model. compute_resource : `skil.resources.compute.ComputeResource' instance, created before running a job. storage_resource : skil.resources.storage.StorageResource instance created before runnning a job output_path : string with path to folder in which job output should be stored. data_set_provider_class : name of the class to be used as DataSetProvider in SKIL is_multi_data_set : boolean, whether data set uses MultiDataSet interface. verbose : boolean, log level. Set True for detailed logging. [source] TrainingJobConfiguration skil.jobs.TrainingJobConfiguration(skil_model, num_epochs, eval_type, eval_data_set_provider_class, compute_resource, storage_resource, output_path, data_set_provider_class, is_multi_data_set=False, ui_url=None, verbose=False) TrainingJobConfiguration Configuration for a SKIL training job. On top of what you need to specify for a base JobConfiguration, you need to set the number of epochs to train for, a (distributed) training configuration and provide information about how to evaluate your model. Arguments: skil_model : a skil.Model instance compute_resource : `skil.resources.compute.ComputeResource' instance, created before running a job. storage_resource : skil.resources.storage.StorageResource instance created before runnning a job output_path : string with path to folder in which job output should be stored. data_set_provider_class : name of the class to be used as DataSetProvider in SKIL is_multi_data_set : boolean, whether data set uses MultiDataSet interface. verbose : boolean, log level. Set True for detailed logging. [source] InferenceJob skil.jobs.InferenceJob(skil, inference_config, job_id=None, create=True) InferenceJob Initialize and run a SKIL inference job. Arguments: inference_config : InferenceJobConfiguration instance job_id : None by default, provide this ID for existing jobs. create : boolean, whether to create a new job or retrieve an existing one. [source] TrainingJob skil.jobs.TrainingJob(skil, training_config, distributed_config=None, job_id=None, create=True) TrainingJob Initialize and run a SKIL training job. Arguments: training_config : TrainingJobConfiguration instance distributed_config : DistributedConfiguration instance job_id : None by default, provide this ID for existing jobs. create : boolean, whether to create a new job or retrieve an existing one.","title":"Jobs"},{"location":"jobs/#skil-jobs","text":"[source]","title":"SKIL Jobs"},{"location":"jobs/#inferencejobconfiguration","text":"skil.jobs.InferenceJobConfiguration(skil_model, batch_size, compute_resource, storage_resource, output_path, data_set_provider_class, is_multi_data_set=False, verbose=False) InferenceJobConfiguration Configuration for a SKIL inference job. On top of what you need to specify for a base JobConfiguration, you need to set the batch size for the model as well. Arguments: skil_model : a skil.Model instance batch_size : int, data batch size to run inference with on the model. compute_resource : `skil.resources.compute.ComputeResource' instance, created before running a job. storage_resource : skil.resources.storage.StorageResource instance created before runnning a job output_path : string with path to folder in which job output should be stored. data_set_provider_class : name of the class to be used as DataSetProvider in SKIL is_multi_data_set : boolean, whether data set uses MultiDataSet interface. verbose : boolean, log level. Set True for detailed logging. [source]","title":"InferenceJobConfiguration"},{"location":"jobs/#trainingjobconfiguration","text":"skil.jobs.TrainingJobConfiguration(skil_model, num_epochs, eval_type, eval_data_set_provider_class, compute_resource, storage_resource, output_path, data_set_provider_class, is_multi_data_set=False, ui_url=None, verbose=False) TrainingJobConfiguration Configuration for a SKIL training job. On top of what you need to specify for a base JobConfiguration, you need to set the number of epochs to train for, a (distributed) training configuration and provide information about how to evaluate your model. Arguments: skil_model : a skil.Model instance compute_resource : `skil.resources.compute.ComputeResource' instance, created before running a job. storage_resource : skil.resources.storage.StorageResource instance created before runnning a job output_path : string with path to folder in which job output should be stored. data_set_provider_class : name of the class to be used as DataSetProvider in SKIL is_multi_data_set : boolean, whether data set uses MultiDataSet interface. verbose : boolean, log level. Set True for detailed logging. [source]","title":"TrainingJobConfiguration"},{"location":"jobs/#inferencejob","text":"skil.jobs.InferenceJob(skil, inference_config, job_id=None, create=True) InferenceJob Initialize and run a SKIL inference job. Arguments: inference_config : InferenceJobConfiguration instance job_id : None by default, provide this ID for existing jobs. create : boolean, whether to create a new job or retrieve an existing one. [source]","title":"InferenceJob"},{"location":"jobs/#trainingjob","text":"skil.jobs.TrainingJob(skil, training_config, distributed_config=None, job_id=None, create=True) TrainingJob Initialize and run a SKIL training job. Arguments: training_config : TrainingJobConfiguration instance distributed_config : DistributedConfiguration instance job_id : None by default, provide this ID for existing jobs. create : boolean, whether to create a new job or retrieve an existing one.","title":"TrainingJob"},{"location":"model/","text":"SKIL Models [source] Model skil.models.Model(model=None, model_id=None, name=None, version=None, experiment=None, labels='', verbose=False, create=True) SKIL wrapper for DL4J, Keras, TensorFlow and other models SKIL has a robust model storage, serving, and import system for supporting major deep learning libraries. SKIL can be used for end-to-end training, configuration, and deployment of models or alternatively you can import models into SKIL. Arguments model : Model file path or Keras model instance model_id : integer. Unique id for model. If None , a unique id will be generated. name : string. Name for the model. version : integer. Version of the model. Defaults to 1. experiment : Experiment instance. If None , an Experiment object will be created internally. labels : string. Labels associated with the workspace, useful for searching (comma seperated). verbose : boolean. If True , prints api response. create : boolean. Internal. Do not use. [source] Transform skil.models.Transform(transform=None, transform_type='CSV', transform_id=None, name=None, version=None, experiment=None, labels='', verbose=False, create=True) SKIL wrapper for for preprocessing (transform) steps. Currently only supports TransformProcess instances from pydatavec or their serialized versions (JSON format). Arguments transform : pydatavec.TransformProcess or TransformProcess JSON transform_id : integer. Unique id for the transform. If None , a unique id will be generated. transform_type : Type of the SKIL transform. Choose from \"CSV\", \"image\" or \"array\" name : string. Name for the transform. version : integer. Version of the transform. Defaults to 1. experiment : Experiment instance. If None , an Experiment object will be created internally. labels : string. Labels associated with the workspace, useful for searching (comma seperated). verbose : boolean. If True , prints api response. create : boolean. Internal. Do not use.","title":"Models"},{"location":"model/#skil-models","text":"[source]","title":"SKIL Models"},{"location":"model/#model","text":"skil.models.Model(model=None, model_id=None, name=None, version=None, experiment=None, labels='', verbose=False, create=True) SKIL wrapper for DL4J, Keras, TensorFlow and other models SKIL has a robust model storage, serving, and import system for supporting major deep learning libraries. SKIL can be used for end-to-end training, configuration, and deployment of models or alternatively you can import models into SKIL. Arguments model : Model file path or Keras model instance model_id : integer. Unique id for model. If None , a unique id will be generated. name : string. Name for the model. version : integer. Version of the model. Defaults to 1. experiment : Experiment instance. If None , an Experiment object will be created internally. labels : string. Labels associated with the workspace, useful for searching (comma seperated). verbose : boolean. If True , prints api response. create : boolean. Internal. Do not use. [source]","title":"Model"},{"location":"model/#transform","text":"skil.models.Transform(transform=None, transform_type='CSV', transform_id=None, name=None, version=None, experiment=None, labels='', verbose=False, create=True) SKIL wrapper for for preprocessing (transform) steps. Currently only supports TransformProcess instances from pydatavec or their serialized versions (JSON format). Arguments transform : pydatavec.TransformProcess or TransformProcess JSON transform_id : integer. Unique id for the transform. If None , a unique id will be generated. transform_type : Type of the SKIL transform. Choose from \"CSV\", \"image\" or \"array\" name : string. Name for the transform. version : integer. Version of the transform. Defaults to 1. experiment : Experiment instance. If None , an Experiment object will be created internally. labels : string. Labels associated with the workspace, useful for searching (comma seperated). verbose : boolean. If True , prints api response. create : boolean. Internal. Do not use.","title":"Transform"},{"location":"resources/","text":"SKIL compute and storage resources [source] DataProc skil.resources.compute.DataProc(skil, name, project_id, region, spark_cluster_name, credential_uri, resource_id=None, create=True) DataProc Google cloud engine DataProc compute resource Arguments: skil : Skil server instance name : Resource name project_id : GCE project ID region : GCE region cluster_name : DataProc cluster name resource_id : optional resource ID to retrieve an existing resource create : boolean, for internal use only. whether to create a new resource or not [source] EMR skil.resources.compute.EMR(skil, name, region, credential_uri, cluster_id=None, resource_id=None, create=True) EMR AWS Elastic Map Reduce compute resource Arguments: skil : Skil server instance name : Name of the resource region : AWS region of the EMR cluster credential_uri : path to credential file cluster_id : ID of the EMR cluster resource_id : optional resource ID to retrieve an existing resource create : boolean, for internal use only. whether to create a new resource or not [source] HDInsight skil.resources.compute.HDInsight(skil, name, subscription_id, resource_group_name, cluster_name, credential_uri, resource_id=None, create=True) HDInsight Azure HDInsight compute resource. Arguments: skil : Skil server instance name : Resource name subscription_id : Azure subscription ID resource_group_name : Resource group name # TODO: is this SKIL or Azure? cluster_name : HDInsight cluster name resource_id : optional resource ID to retrieve an existing resource create : boolean, for internal use only. whether to create a new resource or not [source] YARN skil.resources.compute.YARN(skil, name, local_spark_home, credential_uri, resource_id=None, create=True) YARN YARN compute resource for local Spark computation on YARN. Arguments: skil : Skil server instance name : Resource name local_spark_home : full path to local Spark binary resource_id : optional resource ID to retrieve an existing resource create : boolean, for internal use only. whether to create a new resource or not [source] AzureStorage skil.resources.storage.AzureStorage(skil, name, container_name, credential_uri, resource_id=None, create=True) AzureStorage SKIL Azure storage resource. Arguments: skil : Skil server instance name : Resource name container_name : Azure storage container name resource_id : optional resource ID to retrieve an existing resource create : boolean, for internal use only. whether to create a new resource or not [source] GoogleStorage skil.resources.storage.GoogleStorage(skil, name, project_id, bucket_name, credential_uri, resource_id=None, create=True) GoogleStorage SKIL Google storage resource. Arguments: skil : Skil server instance name : Resource name project_id : Google project ID bucket_name : bucket name resource_id : optional resource ID to retrieve an existing resource create : boolean, for internal use only. whether to create a new resource or not [source] HDFS skil.resources.storage.HDFS(skil, name, name_node_host, name_node_port, credential_uri, resource_id=None, create=True) HDFS SKIL HDFS resource. Arguments: skil : Skil server instance name : Resource name name_node_host : host of the name node name_node_port : port of the name node resource_id : optional resource ID to retrieve an existing resource create : boolean, for internal use only. whether to create a new resource or not [source] S3 skil.resources.storage.S3(skil, name, bucket, region, credential_uri, resource_id=None, create=True) S3 SKIL S3 resource. Arguments: skil : Skil server instance name : Resource name bucket : S3 bucket name region : AWS region resource_id : optional resource ID to retrieve an existing resource create : boolean, for internal use only. whether to create a new resource or not","title":"Resources"},{"location":"resources/#skil-compute-and-storage-resources","text":"[source]","title":"SKIL compute and storage resources"},{"location":"resources/#dataproc","text":"skil.resources.compute.DataProc(skil, name, project_id, region, spark_cluster_name, credential_uri, resource_id=None, create=True) DataProc Google cloud engine DataProc compute resource Arguments: skil : Skil server instance name : Resource name project_id : GCE project ID region : GCE region cluster_name : DataProc cluster name resource_id : optional resource ID to retrieve an existing resource create : boolean, for internal use only. whether to create a new resource or not [source]","title":"DataProc"},{"location":"resources/#emr","text":"skil.resources.compute.EMR(skil, name, region, credential_uri, cluster_id=None, resource_id=None, create=True) EMR AWS Elastic Map Reduce compute resource Arguments: skil : Skil server instance name : Name of the resource region : AWS region of the EMR cluster credential_uri : path to credential file cluster_id : ID of the EMR cluster resource_id : optional resource ID to retrieve an existing resource create : boolean, for internal use only. whether to create a new resource or not [source]","title":"EMR"},{"location":"resources/#hdinsight","text":"skil.resources.compute.HDInsight(skil, name, subscription_id, resource_group_name, cluster_name, credential_uri, resource_id=None, create=True) HDInsight Azure HDInsight compute resource. Arguments: skil : Skil server instance name : Resource name subscription_id : Azure subscription ID resource_group_name : Resource group name # TODO: is this SKIL or Azure? cluster_name : HDInsight cluster name resource_id : optional resource ID to retrieve an existing resource create : boolean, for internal use only. whether to create a new resource or not [source]","title":"HDInsight"},{"location":"resources/#yarn","text":"skil.resources.compute.YARN(skil, name, local_spark_home, credential_uri, resource_id=None, create=True) YARN YARN compute resource for local Spark computation on YARN. Arguments: skil : Skil server instance name : Resource name local_spark_home : full path to local Spark binary resource_id : optional resource ID to retrieve an existing resource create : boolean, for internal use only. whether to create a new resource or not [source]","title":"YARN"},{"location":"resources/#azurestorage","text":"skil.resources.storage.AzureStorage(skil, name, container_name, credential_uri, resource_id=None, create=True) AzureStorage SKIL Azure storage resource. Arguments: skil : Skil server instance name : Resource name container_name : Azure storage container name resource_id : optional resource ID to retrieve an existing resource create : boolean, for internal use only. whether to create a new resource or not [source]","title":"AzureStorage"},{"location":"resources/#googlestorage","text":"skil.resources.storage.GoogleStorage(skil, name, project_id, bucket_name, credential_uri, resource_id=None, create=True) GoogleStorage SKIL Google storage resource. Arguments: skil : Skil server instance name : Resource name project_id : Google project ID bucket_name : bucket name resource_id : optional resource ID to retrieve an existing resource create : boolean, for internal use only. whether to create a new resource or not [source]","title":"GoogleStorage"},{"location":"resources/#hdfs","text":"skil.resources.storage.HDFS(skil, name, name_node_host, name_node_port, credential_uri, resource_id=None, create=True) HDFS SKIL HDFS resource. Arguments: skil : Skil server instance name : Resource name name_node_host : host of the name node name_node_port : port of the name node resource_id : optional resource ID to retrieve an existing resource create : boolean, for internal use only. whether to create a new resource or not [source]","title":"HDFS"},{"location":"resources/#s3","text":"skil.resources.storage.S3(skil, name, bucket, region, credential_uri, resource_id=None, create=True) S3 SKIL S3 resource. Arguments: skil : Skil server instance name : Resource name bucket : S3 bucket name region : AWS region resource_id : optional resource ID to retrieve an existing resource create : boolean, for internal use only. whether to create a new resource or not","title":"S3"},{"location":"service/","text":"SKIL Services [source] Service skil.services.Service(skil, model, deployment, model_deployment) A service is a deployed model. Arguments: skil : Skil server instance model : skil.Model instance deployment : skil.Deployment instance model_deployment : result of deploy_model API call of a model [source] TransformCsvService skil.services.TransformCsvService(skil, model, deployment, model_deployment) TransformCsvService A service for transforming CSV data Arguments: skil : Skil server instance model : skil.Model instance deployment : skil.Deployment instance model_deployment : result of deploy_model API call of a model [source] TransformArrayService skil.services.TransformArrayService(skil, model, deployment, model_deployment) A service for transforming array data Arguments: skil : Skil server instance model : skil.Model instance deployment : skil.Deployment instance model_deployment : result of deploy_model API call of a model [source] TransformArrayService skil.services.TransformArrayService(skil, model, deployment, model_deployment) A service for transforming array data Arguments: skil : Skil server instance model : skil.Model instance deployment : skil.Deployment instance model_deployment : result of deploy_model API call of a model","title":"Services"},{"location":"service/#skil-services","text":"[source]","title":"SKIL Services"},{"location":"service/#service","text":"skil.services.Service(skil, model, deployment, model_deployment) A service is a deployed model. Arguments: skil : Skil server instance model : skil.Model instance deployment : skil.Deployment instance model_deployment : result of deploy_model API call of a model [source]","title":"Service"},{"location":"service/#transformcsvservice","text":"skil.services.TransformCsvService(skil, model, deployment, model_deployment) TransformCsvService A service for transforming CSV data Arguments: skil : Skil server instance model : skil.Model instance deployment : skil.Deployment instance model_deployment : result of deploy_model API call of a model [source]","title":"TransformCsvService"},{"location":"service/#transformarrayservice","text":"skil.services.TransformArrayService(skil, model, deployment, model_deployment) A service for transforming array data Arguments: skil : Skil server instance model : skil.Model instance deployment : skil.Deployment instance model_deployment : result of deploy_model API call of a model [source]","title":"TransformArrayService"},{"location":"service/#transformarrayservice_1","text":"skil.services.TransformArrayService(skil, model, deployment, model_deployment) A service for transforming array data Arguments: skil : Skil server instance model : skil.Model instance deployment : skil.Deployment instance model_deployment : result of deploy_model API call of a model","title":"TransformArrayService"},{"location":"skil/","text":"[source] Skil skil.base.Skil(workspace_server_id=None, host='localhost', port=9008, debug=False, user_id='admin', password='admin') Central class for managing connections with the SKIL server. Arguments workspace_server_id : None by default, only specify if you want to connect to a non-default SKIL workspace server. host : string, Host on which the SKIL server runs. port : integer, Port on which the SKIL host runs. debug : boolean, set to false for more verbose logging. user_id : user name for your SKIL server connection. password : password of the provided SKIL user.","title":"SKIL servers"},{"location":"skil/#skil","text":"skil.base.Skil(workspace_server_id=None, host='localhost', port=9008, debug=False, user_id='admin', password='admin') Central class for managing connections with the SKIL server. Arguments workspace_server_id : None by default, only specify if you want to connect to a non-default SKIL workspace server. host : string, Host on which the SKIL server runs. port : integer, Port on which the SKIL host runs. debug : boolean, set to false for more verbose logging. user_id : user name for your SKIL server connection. password : password of the provided SKIL user.","title":"Skil"},{"location":"spark/","text":"[source] ParameterAveraging skil.spark.ParameterAveraging(num_workers, batch_size, averaging_frequency=5, num_batches_prefetch=0, collect_stats=False) Parameter averaging configuration for distributed training. Arguments: num_workers : number of Spark workers/executors. batch_size : batch size used for model training averaging_frequency : int, after how many batches of training averaging takes place num_batches_prefetch : int, how many batches to pre-fetch, deactivated if 0. collect_stats : boolean, if statistics get collected during training [source] ParameterSharing skil.spark.ParameterSharing(num_workers, batch_size, shake_frequency=0, min_threshold=1e-05, update_threshold=0.001, workers_per_node=-1, num_batches_prefetch=0, step_delay=50, step_trigger=0.05, threshold_step=1e-05, collect_stats=False) Parameter sharing configuration for distributed training. Arguments: num_workers : number of Spark workers/executors. batch_size : batch size used for model training shake_frequency : shake frequency min_threshold : minimum threshold update_threshold : update threshold workers_per_node : workers per node num_batches_prefetch : number of batches to prefetch step_delay : step delay step_trigger : step trigger threshold_step : threshold step collect_stats : boolean, if statistics get collected during training","title":"Distributed training"},{"location":"spark/#parameteraveraging","text":"skil.spark.ParameterAveraging(num_workers, batch_size, averaging_frequency=5, num_batches_prefetch=0, collect_stats=False) Parameter averaging configuration for distributed training. Arguments: num_workers : number of Spark workers/executors. batch_size : batch size used for model training averaging_frequency : int, after how many batches of training averaging takes place num_batches_prefetch : int, how many batches to pre-fetch, deactivated if 0. collect_stats : boolean, if statistics get collected during training [source]","title":"ParameterAveraging"},{"location":"spark/#parametersharing","text":"skil.spark.ParameterSharing(num_workers, batch_size, shake_frequency=0, min_threshold=1e-05, update_threshold=0.001, workers_per_node=-1, num_batches_prefetch=0, step_delay=50, step_trigger=0.05, threshold_step=1e-05, collect_stats=False) Parameter sharing configuration for distributed training. Arguments: num_workers : number of Spark workers/executors. batch_size : batch size used for model training shake_frequency : shake frequency min_threshold : minimum threshold update_threshold : update threshold workers_per_node : workers per node num_batches_prefetch : number of batches to prefetch step_delay : step delay step_trigger : step trigger threshold_step : threshold step collect_stats : boolean, if statistics get collected during training","title":"ParameterSharing"},{"location":"training/","text":"Getting started with training jobs in SKIL","title":"SKIL training"},{"location":"training/#getting-started-with-training-jobs-in-skil","text":"","title":"Getting started with training jobs in SKIL"},{"location":"work_space/","text":"SKIL Workspaces [source] WorkSpace skil.workspaces.WorkSpace(skil=None, name=None, labels=None, verbose=False, create=True) WorkSpace Workspaces are a collection of features that enable different tasks such as conducting experiments, training models, and test different dataset transforms. Workspaces are distinct from Deployments by operating as a space for non-production work. Arguments skil : Skil server instance name : string. Name for the workspace. labels : string. Labels associated with the workspace, useful for searching (comma seperated). verbose : boolean. If True, api response will be printed. create : boolean. Internal, do not use.","title":"Workspaces"},{"location":"work_space/#skil-workspaces","text":"[source]","title":"SKIL Workspaces"},{"location":"work_space/#workspace","text":"skil.workspaces.WorkSpace(skil=None, name=None, labels=None, verbose=False, create=True) WorkSpace Workspaces are a collection of features that enable different tasks such as conducting experiments, training models, and test different dataset transforms. Workspaces are distinct from Deployments by operating as a space for non-production work. Arguments skil : Skil server instance name : string. Name for the workspace. labels : string. Labels associated with the workspace, useful for searching (comma seperated). verbose : boolean. If True, api response will be printed. create : boolean. Internal, do not use.","title":"WorkSpace"}]}